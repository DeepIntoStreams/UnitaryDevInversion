{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138725,
     "status": "ok",
     "timestamp": 1707398515422,
     "user": {
      "displayName": "Zijiu Lyu",
      "userId": "00923613968883554039"
     },
     "user_tz": -480
    },
    "id": "g39WTlfmS85d",
    "outputId": "a4e7dbf6-342a-456f-9623-571bdb463c5e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from src.char_func import char_func_path\n",
    "from src.utils import FBM_data, subsample\n",
    "\n",
    "\n",
    "class Compare_test_metrics:\n",
    "    def __init__(self, X, Y1, Y2, device):\n",
    "        self.X = X\n",
    "        self.Y1 = Y1\n",
    "        self.Y2 = Y2\n",
    "        self.device = device\n",
    "\n",
    "    def permutation_test(self, test_func, num_exp, num_perm, sample_size):\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "\n",
    "            true_rej = 0  # power\n",
    "            false_rej = 0  # type 1 error\n",
    "            for i in tqdm(range(num_exp)):\n",
    "                X = subsample(self.X, sample_size)\n",
    "                Y1 = subsample(self.Y1, sample_size)\n",
    "                Y2 = subsample(self.Y2, sample_size)\n",
    "                X = X.to(self.device)\n",
    "                Y1 = Y1.to(self.device)\n",
    "                Y2 = Y2.to(self.device)\n",
    "\n",
    "                H0_stats = []\n",
    "                H1_stats = []\n",
    "                for _ in range(num_perm):\n",
    "                    idx = torch.randperm(2 * sample_size)\n",
    "\n",
    "                    combined = torch.cat([Y1, Y2])\n",
    "                    H0_stats.append(\n",
    "                        test_func(combined[idx[:sample_size]], combined[\n",
    "                            idx[sample_size:]]).cpu().detach().numpy().item())\n",
    "\n",
    "                    combined = torch.cat([X, Y1])\n",
    "                    H1_stats.append(\n",
    "                        test_func(combined[idx[:sample_size]], combined[\n",
    "                            idx[sample_size:]]).cpu().detach().numpy().item())\n",
    "\n",
    "                if test_func(Y1, Y2) > np.quantile(H0_stats, 0.95):\n",
    "                    false_rej += 1\n",
    "                if test_func(X, Y1) > np.quantile(H1_stats, 0.95):\n",
    "                    true_rej += 1\n",
    "\n",
    "            power = true_rej / num_exp\n",
    "            type1_error = false_rej / num_exp\n",
    "            end = time.time()\n",
    "\n",
    "        return power, type1_error, end - start\n",
    "\n",
    "    def run_HT(self,\n",
    "               train_X,\n",
    "               train_Y,\n",
    "               num_exp=20,\n",
    "               num_perm=500,\n",
    "               sample_size=200,\n",
    "               tag=None,\n",
    "               num_samples_u=None,\n",
    "               hidden_size_u=None,\n",
    "               num_samples_so=None,\n",
    "               hidden_size_so=None,\n",
    "               num_samples_d=None,\n",
    "               hidden_size_d=None,\n",
    "               batch_size=None,\n",
    "               max_iter=2000):\n",
    "        model = []\n",
    "        power = []\n",
    "        type1_error = []\n",
    "        times = []\n",
    "        infer_times = []\n",
    "        tags = []\n",
    "\n",
    "        ##########################################################################################################################################\n",
    "        # 1. PCFD\n",
    "        train_X_dl = DataLoader(train_X.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "        train_Y_dl = DataLoader(train_Y.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "\n",
    "        initial_char_func = char_func_path(num_samples=num_samples_u,\n",
    "                                           hidden_size=hidden_size_u,\n",
    "                                           lie_group='unitary',\n",
    "                                           input_size=self.X.shape[-1],\n",
    "                                           add_time=True,\n",
    "                                           init_range=1).to(self.device)\n",
    "\n",
    "        char_optimizer = torch.optim.Adam(initial_char_func.parameters(),\n",
    "                                          betas=(0, 0.9),\n",
    "                                          lr=0.05)\n",
    "\n",
    "        start_u = time.time()\n",
    "        for i in tqdm(range(max_iter)):\n",
    "            X = next(iter(train_X_dl))\n",
    "            Y = next(iter(train_Y_dl))\n",
    "            char_optimizer.zero_grad()\n",
    "            char_loss = -initial_char_func.distance_measure(X, Y, Lambda=0)\n",
    "            char_loss.backward()\n",
    "            char_optimizer.step()\n",
    "        end_u = time.time()\n",
    "\n",
    "        untrained_power, untrained_t1error, infer_time = self.permutation_test(\n",
    "            partial(initial_char_func.distance_measure, Lambda=0),\n",
    "            num_exp,\n",
    "            num_perm,\n",
    "            sample_size,\n",
    "        )\n",
    "        model.append('PCFD')\n",
    "        power.append(untrained_power)\n",
    "        type1_error.append(untrained_t1error)\n",
    "        times.append(end_u - start_u)\n",
    "        infer_times.append(infer_time)\n",
    "        tags.append(tag)\n",
    "        ##########################################################################################################################################\n",
    "        # 2. OPCFD\n",
    "        train_X_dl = DataLoader(train_X.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "        train_Y_dl = DataLoader(train_Y.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "\n",
    "        initial_char_func_so = char_func_path(num_samples=num_samples_so,\n",
    "                                              hidden_size=hidden_size_so,\n",
    "                                              lie_group='orthogonal',\n",
    "                                              input_size=self.X.shape[-1],\n",
    "                                              add_time=True,\n",
    "                                              init_range=1).to(self.device)\n",
    "\n",
    "        char_optimizer_so = torch.optim.Adam(initial_char_func_so.parameters(),\n",
    "                                             betas=(0, 0.9),\n",
    "                                             lr=0.05)\n",
    "\n",
    "        start_so = time.time()\n",
    "        for i in tqdm(range(max_iter)):\n",
    "            X = next(iter(train_X_dl))\n",
    "            Y = next(iter(train_Y_dl))\n",
    "            char_optimizer_so.zero_grad()\n",
    "            char_loss_so = -initial_char_func_so.distance_measure(\n",
    "                X, Y, Lambda=0)\n",
    "            char_loss_so.backward()\n",
    "            char_optimizer_so.step()\n",
    "        end_so = time.time()\n",
    "\n",
    "        untrained_power_so, untrained_t1error_so, infer_time = self.permutation_test(\n",
    "            partial(initial_char_func_so.distance_measure, Lambda=0),\n",
    "            num_exp,\n",
    "            num_perm,\n",
    "            sample_size,\n",
    "        )\n",
    "        model.append('OPCFD')\n",
    "        power.append(untrained_power_so)\n",
    "        type1_error.append(untrained_t1error_so)\n",
    "        times.append(end_so - start_so)\n",
    "        infer_times.append(infer_time)\n",
    "        tags.append(tag)\n",
    "        ##########################################################################################################################################\n",
    "        # 3. RPCFD\n",
    "        train_X_dl = DataLoader(train_X.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "        train_Y_dl = DataLoader(train_Y.to(self.device),\n",
    "                                batch_size,\n",
    "                                shuffle=True)\n",
    "\n",
    "        initial_char_func_diag = char_func_path(\n",
    "            num_samples=num_samples_d,\n",
    "            hidden_size=hidden_size_d,\n",
    "            lie_group='orthogonal_diag',\n",
    "            input_size=self.X.shape[-1],\n",
    "            add_time=True,\n",
    "            init_range=1,\n",
    "        ).to(self.device)\n",
    "\n",
    "        char_optimizer_diag = torch.optim.Adam(\n",
    "            initial_char_func_diag.parameters(), betas=(0, 0.9), lr=0.5)\n",
    "\n",
    "        start_diag = time.time()\n",
    "        for i in tqdm(range(max_iter)):\n",
    "            X = next(iter(train_X_dl))\n",
    "            Y = next(iter(train_Y_dl))\n",
    "            char_optimizer_diag.zero_grad()\n",
    "            char_loss_diag = -initial_char_func_diag.distance_measure(\n",
    "                X, Y, Lambda=0)\n",
    "            char_loss_diag.backward()\n",
    "            char_optimizer_diag.step()\n",
    "        end_diag = time.time()\n",
    "\n",
    "        untrained_power_diag, untrained_t1error_diag, infer_time = self.permutation_test(\n",
    "            partial(initial_char_func_diag.distance_measure, Lambda=0),\n",
    "            num_exp,\n",
    "            num_perm,\n",
    "            sample_size,\n",
    "        )\n",
    "        model.append('RPCFD')\n",
    "        power.append(untrained_power_diag)\n",
    "        type1_error.append(untrained_t1error_diag)\n",
    "        times.append(end_diag - start_diag)\n",
    "        infer_times.append(infer_time)\n",
    "        tags.append(tag)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'model': model,\n",
    "            'power': power,\n",
    "            'type1 error': type1_error,\n",
    "            'opt time': times,\n",
    "            'infer time': infer_times,\n",
    "            'tag': tags\n",
    "        })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "\n",
    "    max_iter = 500\n",
    "    df_list = []\n",
    "    for i in range(10):\n",
    "        for h in [\n",
    "                0.2, 0.25, 0.3, 0.35, 0.4, 0.425, 0.45, 0.475, 0.5, 0.525,\n",
    "                0.55, 0.575, 0.6, 0.65, 0.7, 0.75, 0.8\n",
    "        ]:\n",
    "            for dim in [5]:\n",
    "                print('h =', h)\n",
    "                print('dim =', dim)\n",
    "                print('trial =', i + 1)\n",
    "\n",
    "                train_X = FBM_data(10000, dim=3, length=50, h=0.5)\n",
    "                train_Y = FBM_data(10000, dim=3, length=50, h=h)\n",
    "\n",
    "                X = FBM_data(10000, dim=3, length=50, h=0.5)\n",
    "                Y1 = FBM_data(10000, dim=3, length=50, h=h)\n",
    "                Y2 = FBM_data(10000, dim=3, length=50, h=h)\n",
    "\n",
    "                df = Compare_test_metrics(X, Y1, Y2, device).run_HT(\n",
    "                    train_X=train_X,\n",
    "                    train_Y=train_Y,\n",
    "                    num_exp=20,\n",
    "                    num_perm=500,\n",
    "                    sample_size=200,\n",
    "                    tag=h,\n",
    "                    num_samples_u=8,\n",
    "                    hidden_size_u=dim,\n",
    "                    num_samples_so=8,\n",
    "                    hidden_size_so=dim,\n",
    "                    num_samples_d=8,\n",
    "                    hidden_size_d=dim,\n",
    "                    batch_size=1024,\n",
    "                    max_iter=max_iter,\n",
    "                )\n",
    "                print(df)\n",
    "                df_list.append(df)\n",
    "                df = pd.concat(df_list)\n",
    "\n",
    "                if not os.path.exists('numerical_results'):\n",
    "                    os.mkdir('numerical_results')\n",
    "                df.to_csv(\n",
    "                    f'numerical_results/trial={i + 1} h={h} dim={dim}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
